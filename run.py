import json, time
from test.test_service_mock import service

import streamlit as st
import streamlit.components.v1 as components
from langchain.chat_models.gigachat import GigaChat
from core.chat import TaskLoader

import core.lib.streamlit.components as st_inner
from core import critique, front
from core.lib.streamlit import utils
from core.chat import Chat, Message, Task
from core.lib import constants, datacls, exercise
from core.lib.exercise.default import dialog
from core.lib.pipeline import Pipeline
from core.service import Service, ServiceResponseModel

# –û–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="RapportTop",
    page_icon="üë®‚Äçüíº"
)

# main.css
st.markdown(
    front.main_css,
    unsafe_allow_html=True,
)

try:  # –°–∫—Ä—ã–≤–∞–µ–º –≤—Å–µ –≤–∏–¥–∏–º—ã–µ –æ—à–∏–±–∫–∏ UI
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–∫–Ω–æ–ø–∫–∞ –∑–∞–ø–∏—Å–∏ / –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è)
    record_button = components.declare_component("custom_input", path="build")
    context = st.session_state
    secrets = st.secrets

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Ç–∞
    if context.get("chat") is None:
        context.chat = Chat(context=context)
        context.service = Service(context=context, secrets=secrets)

        # << ----- –ß—Ç–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ----- >>
        # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–≤–æ–¥–∏—Ç—Å—è –ø–æ–¥ title, —É–∫–∞–∑–∞–Ω –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é –±–∏–∑–Ω–µ—Å–∞
        context.comment = st.query_params.get("comment")
        context.course_id = st.query_params.get("course_id", 3)

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤
        if context.course_id:
            context.tasks = TaskLoader(context=context, secrets=secrets).load()
        else: # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–µ—Ç—Ç–∏–Ω–≥ –∑–∞–¥–∞—á
            context.tasks = [Task(**item) for item in dialog]
        assert len(context.tasks), "No tasks provided!"

        context.progress_text = "" # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä–∞
        context.current_task_index = -1  # –ò–Ω–¥–µ–∫—Å –∏—Å–ø–æ–ª–Ω—è–µ–º–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞
        context.task_scores = []  # –°—á—ë—Ç –±–∞–ª–ª–æ–≤ –∑–∞ –∑–∞–¥–∞–Ω–∏—è
        context.synchronize = False
        context.streamlit_crutch = False

        # << ----- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π ----- >>
        model_config = dict(
            credentials=st.secrets["GIGAAUTH"],
            verify_ssl_certs=False,
            scope="GIGACHAT_API_CORP",
            temperature=1e-8,
            model="GigaChat-Max",
        )

        # –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
        context.pro_model = GigaChat(**model_config)
        # Lite –º–æ–¥–µ–ª—å
        del model_config["model"]
        context.lite_model = GigaChat(**model_config)

        context.pipeline = Pipeline()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö —Å—Ç–µ–ø–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏
        context.pipeline.steps.extend(
            [
                critique.EloquenceProcessor(
                    model=context.pro_model,
                ),
                critique.SemanticSimProcessor(
                    model=context.pro_model,
                    emb_secret=secrets["GIGAAUTH"],
                ),
                critique.–°–°SProcessor(model=context.pro_model),
                critique.IntonProcessor(context=context),
                critique.TempProcessor(context=context),
                critique.FriendlinessProcessor(context=context),
            ]
        )
        
        context.typo_processor = critique.TypoProcessor(model=context.lite_model)

        # << ----- –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ "ready" –≤ LMS ----- >>
        status = datacls.Status(status="ready")
        st_inner.run_js_script(status.model_dump_json())

    if context.comment:
        st.markdown(context.comment)
    st.header("–¢—Ä–µ–Ω–∞–∂—ë—Ä –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞")
    
    chat = context.chat
    pipeline = context.pipeline

    top_container = st.empty()
    # Not comment –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–µ
    if chat.n_messages == 0 and not context.comment:
        top_container.image("core/front/img/chat_bg.svg", use_container_width=True)
    elif chat.n_messages == 0 and context.comment:
        top_container.empty()
    elif context.current_task_index + 1 <= len(context.tasks):
        progress_text = f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {context.current_task_index + 1}/{len(context.tasks)}"
        top_container.progress((context.current_task_index + 1) / len(context.tasks), text=progress_text)

    delay_to_record = chat.show()

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    if context.current_task_index < chat.n_tasks:
        if context.get("recorded_audio") is not None:
            record = context.recorded_audio

            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ASR –æ—Ç–≤–µ—Ç–∞ —É—á–µ–Ω–∏–∫–∞
            role = "user"
            avatar = "üë®‚Äçüè´"
            with st.chat_message(name=role, avatar=avatar):
                with st.spinner(text="–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ..."):
                    result: int | ServiceResponseModel | str = context.service.run(record, context.current_task.right_answer)

                    if isinstance(result, str):
                        st.write("–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ —Ö–æ—Ä–æ—à–µ–º –∫–∞—á–µ—Å—Ç–≤–µ –∑–∞–ø–∏—Å–∏ —Å –≤–∞—à–µ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞.")
                        st.audio(f"{secrets['ZAIKANIE_URL']}/{result}", autoplay=True)
                        
                        # –ü–æ–∫–∞–∑–∞—Ç—å –∞—É–¥–∏–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                        st.markdown(
                            front.show_audio_css,
                            unsafe_allow_html=True,
                        )
                        st.button(
                            "‚Üª –ü–æ–≤—Ç–æ—Ä",
                            on_click=lambda: utils.reset_empty_input(context),
                            key="empty_reset",
                            use_container_width=True,
                        )
                        raise(LookupError("Bad recognition")) # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –±–µ–∑ –æ—à–∏–±–æ–∫
                    elif result == 500:
                        raise(RuntimeError("500 Remote Service Response"))
                    else:
                        _, result.texts[0] = context.typo_processor.run_model(result.texts[0])
                        st.write(result.texts[0])
                        context.service_result = result

                        message = Message(
                            role=role,
                            avatar=avatar,
                            content_type=["text"],
                            content=[result.texts[0]],
                        )

                        chat.add_message(message=message)

            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
            role = "assistant"
            avatar = "ü§ñ"
            with st.chat_message(name=role, avatar=avatar):
                with st.spinner(text="–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∞—à –æ—Ç–≤–µ—Ç..."):
                    scores, responses, step_success = pipeline.run(context=context)
                task_score = min(
                    round(sum(scores) / sum(step_success)),
                    constants.MAX_TASK_SCORE,
                )
                score_string = exercise.score_message.format(
                    task_score=task_score, max_score=constants.MAX_TASK_SCORE
                )
                text = constants.LF.join(
                    [constants.CHAT_PREFIX, *responses, score_string]
                )

                right_answer_expander = {
                    "label": "–í–µ—Ä–Ω—ã–π –æ—Ç–≤–µ—Ç",
                    "text": context.current_task.right_answer,
                }

                message = Message(
                    role=role,
                    avatar=avatar,
                    content_type=["text", "expand"],
                    content=[text, right_answer_expander],
                )

                chat.add_message(message=message)
                context.task_scores.append(task_score)

                # –û—á–∏—â–∞—é –∑–Ω–∞—á–µ–Ω–∏–µ –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫ —Ç–æ–≥–æ, —á—Ç–æ –æ–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
                context.recorded_audio = None
                st.rerun()

        if not context.get("continueMode", True):
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–Ω–æ–ø–∫–∏ –∑–∞–ø–∏—Å–∏ –Ω—É–∂–Ω–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —É—á–µ–Ω–∏–∫ –¥–æ—Å–ª—É—à–∞–ª –∑–∞–ø–∏—Å—å
            if not context.streamlit_crutch: # –ö–æ—Å—Ç—ã–ª—å –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã 
                time.sleep(delay_to_record)
            else:
                context.streamlit_crutch = False

            record_button(
                key="recorded_audio", continueMode=False, state=context.synchronize
            )

            context.continueMode = True
            if context.synchronize:
                context.continueMode = False
                context.synchronize = False
                context.streamlit_crutch = True
                st.rerun()
        else:
            # –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –∑–∞–¥–∞–Ω–∏—é
            context.current_task_index += 1

            if context.current_task_index == chat.n_tasks:
                st.rerun()  # –°–∫—Ä—ã—Ç—å –∫–Ω–æ–ø–∫—É

            context.current_task = context.tasks[context.current_task_index]

            message = Message(
                role="assistant",
                avatar="üë®‚Äçüíº",
                content_type=["text", "audio"],
                content=[context.current_task.message, context.current_task.audio],
            )
            chat.add_message(message)
            record_button(key="continueMode", continueMode=True)
        # –°–∫—Ä–æ–ª–ª –≤–Ω–∏–∑
        st_inner.run_js_script(front.scroll)

    else:
        # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –µ–≥–æ LMS
        role = "assistant"
        avatar = "ü§ñ"
        with st.chat_message(name=role, avatar=avatar):
            percent_result = round(sum(context.task_scores) / chat.n_tasks, 2)

            st.write("–ó–∞–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, —Å–ø–∞—Å–∏–±–æ!")
            st.markdown(
                f"""<h1 align="center">–í–∞—à –±–∞–ª–ª: {percent_result}%</h1>""",
                unsafe_allow_html=True,
            )

            # –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Å–µ—Ä–≤–µ—Ä
            response = datacls.ResultData(
                score=sum(context.task_scores),
                max_score=len(context.task_scores) * constants.MAX_TASK_SCORE,
            )

            compiled_result_script = front.post_message_template.format(
                response_json=response.model_dump_json()
            )
            st_inner.run_js_script(compiled_result_script)
        # –°–∫—Ä–æ–ª–ª –≤–Ω–∏–∑
        st_inner.run_js_script(front.scroll)
except LookupError:
    st.stop()
# except Exception as e:
#     print(e)
#     st.error("Internal server error")
#     st.stop()
